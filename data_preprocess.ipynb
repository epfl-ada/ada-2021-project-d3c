{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T16:40:39.263771Z",
     "start_time": "2021-11-08T16:40:38.664657Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tld import get_tld\n",
    "import tldextract\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dask\n",
    "import bz2\n",
    "import json\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T16:40:52.012609Z",
     "start_time": "2021-11-08T16:40:39.683767Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nationality</th>\n",
       "      <th>gender</th>\n",
       "      <th>party</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q161885, Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>[Q327591]</td>\n",
       "      <td>Q23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q145]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q31]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>[Q29468]</td>\n",
       "      <td>Q207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q29]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055976</th>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055977</th>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055978</th>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055979</th>\n",
       "      <td>None</td>\n",
       "      <td>[Q6581072]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9055980</th>\n",
       "      <td>[Q30]</td>\n",
       "      <td>[Q6581097]</td>\n",
       "      <td>None</td>\n",
       "      <td>Q106406643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9055981 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            nationality      gender      party          id\n",
       "0        [Q161885, Q30]  [Q6581097]  [Q327591]         Q23\n",
       "1                [Q145]  [Q6581097]       None         Q42\n",
       "2                 [Q31]  [Q6581097]       None       Q1868\n",
       "3                 [Q30]  [Q6581097]   [Q29468]        Q207\n",
       "4                 [Q29]  [Q6581097]       None        Q297\n",
       "...                 ...         ...        ...         ...\n",
       "9055976           [Q30]  [Q6581097]       None  Q106406560\n",
       "9055977           [Q30]  [Q6581097]       None  Q106406571\n",
       "9055978            None  [Q6581072]       None  Q106406588\n",
       "9055979            None  [Q6581072]       None  Q106406593\n",
       "9055980           [Q30]  [Q6581097]       None  Q106406643\n",
       "\n",
       "[9055981 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"E:\\\\PycharmProject\\\\ada_project\\\\data\\\\speaker_attributes.parquet\"\n",
    "\n",
    "# load the speakers' qid data, \n",
    "wiki_data = pd.read_parquet(path, engine='pyarrow')\n",
    "# we only takes speakers nationality, gender, and party into considerations.\n",
    "wiki_data = wiki_data[['nationality','gender','party', 'id']]\n",
    "wiki_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T16:40:52.028611Z",
     "start_time": "2021-11-08T16:40:52.014610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extract urls domains, which could be used to obtain the news publishers.\n",
    "def extract_domain(data):\n",
    "    all_domains = []\n",
    "    for idx, row in tqdm(data.iterrows()):  # for a single quotation\n",
    "        domains = []\n",
    "        for url in row['urls']:\n",
    "            res=tldextract.extract(url)\n",
    "            domain = res.domain\n",
    "            domains.append(domain)\n",
    "        all_domains.append(domains) \n",
    "    all_domains = pd.Series(all_domains)\n",
    "    data['domains'] = all_domains\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T16:40:52.044609Z",
     "start_time": "2021-11-08T16:40:52.031611Z"
    }
   },
   "outputs": [],
   "source": [
    "def map_qid2value(data):\n",
    "    # map the qid to it's corresponding real value\n",
    "    party_mapper = pd.read_csv('party_mapper.csv', index_col=0)\n",
    "    party_mapper = party_mapper['Label'].to_dict()\n",
    "    gender_mapper = pd.read_csv('gender_mapper.csv', index_col=0)\n",
    "    gender_mapper = gender_mapper['Label'].to_dict()\n",
    "    nationality_mapper = pd.read_csv('nationality_mapper.csv', index_col=0)\n",
    "    nationality_mapper = nationality_mapper['Label'].to_dict()\n",
    "    \n",
    "    data.party.replace(party_mapper, inplace=True)\n",
    "    data.gender.replace(gender_mapper, inplace=True)\n",
    "    data.nationality.replace(nationality_mapper, inplace=True)\n",
    "    return data\n",
    "\n",
    "def merge_with_wiki(data, wiki_data):\n",
    "    # merge the original quote-bank data with wiki-data\n",
    "    \n",
    "    # this function is used to extract the first elements in a column which may contains \n",
    "    # multiple values for each row.\n",
    "    func = lambda x: list(x)[0] if x is not None and x is not np.nan else x\n",
    "    \n",
    "    # for speaker with multiple qids, we only take the first one as real value because we assume that \n",
    "    # wiki sort the qids based on their popularity, so the first one have large likely to be the ground truth qid.\n",
    "    data['qids'] = data.qids.apply(func)\n",
    "    merge_data = data.merge(wiki_data, left_on='qids', right_on='id', how='left')\n",
    "    \n",
    "    merge_data.party = merge_data.party.apply(func)\n",
    "    merge_data.gender = merge_data.gender.apply(func)\n",
    "    merge_data.nationality = merge_data.nationality.apply(func) \n",
    "    \n",
    "    merge_data = map_qid2value(merge_data)\n",
    "\n",
    "    return merge_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We found that a large number of elements in speaker column are None, however, it provides nothing useful for analysis, so we filter it out. Besides, we notice that there are different forms for the name of Donald Trump, such as *President Donald Trump*, *President Trump* and so on. Therefore, We replace all names containing 'Trump' by 'Donald Trump' for consistency. But it's hard for us to deal with other situations because it is unlikely to find all different names which actually mean the same person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-08T16:40:52.060649Z",
     "start_time": "2021-11-08T16:40:52.045609Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, wiki_data):\n",
    "    # for simpification, we drop quotations that do not contains speakers \n",
    "    data = data[data['speaker'] != 'None']\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    # these two columns may be useless for us.\n",
    "    data = data.drop(['probas', 'phase'], axis=1)\n",
    "    \n",
    "    data['speaker'] = data['speaker'].apply(lambda x: 'Donald Trump' if 'Trump' in x else x)\n",
    "    \n",
    "    # Replace '[ ]' in the quotation by ''\n",
    "    tmp = data['quotation'].str.replace('[', '')\n",
    "    tmp = tmp.str.replace(']', '')\n",
    "    data['quotation'] = tmp\n",
    "    \n",
    "    data = extract_domain(data)\n",
    "    \n",
    "    # urls now becomes useless for us\n",
    "    data = data.drop(['urls'], axis=1)\n",
    "    \n",
    "    data = merge_with_wiki(data, wiki_data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"E:\\\\PycharmProject\\\\ada_project\\\\data\\\\\"\n",
    "# chunk_list = []\n",
    "\n",
    "# self defined data processing pipeline with chunk, \n",
    "# the original chunk methods provided bu pandas did not solve the OutofNemory error.\n",
    "with bz2.open(path + 'quotes-2019.json.bz2', 'r') as f:\n",
    "    lines = []\n",
    "    chunk_size = 1e6\n",
    "    chunk_num = 1\n",
    "    for i, line in enumerate(f):\n",
    "        dic = json.loads(line)\n",
    "        lines.append(dic)\n",
    "        if i > 0 and i % chunk_size == 0:\n",
    "            print('*' * 10 + str(chunk_num) + '-th chunk' + '*' * 10)\n",
    "            chunk = pd.DataFrame(lines)\n",
    "            processed_chunk = preprocess_data(chunk, wiki_data)\n",
    "            if chunk_num == 1:\n",
    "                processed_chunk.to_csv(path + 'processed-quotes-2019.csv', mode='a', index=False)\n",
    "            else:\n",
    "                processed_chunk.to_csv(path + 'processed-quotes-2019.csv', mode='a', header=False, index=False)\n",
    "\n",
    "            lines = []\n",
    "            chunk_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}